package ch.ahdis.matchbox.validation.matchspark;

import ch.ahdis.matchbox.CliContext;

import java.io.IOException;

import dev.langchain4j.data.message.SystemMessage;
import dev.langchain4j.data.message.UserMessage;
import dev.langchain4j.memory.ChatMemory;
import dev.langchain4j.memory.chat.MessageWindowChatMemory;
import dev.langchain4j.model.anthropic.AnthropicChatModel;
import dev.langchain4j.model.chat.ChatLanguageModel;
import dev.langchain4j.model.chat.request.ChatRequest;
import dev.langchain4j.model.chat.response.ChatResponse;
import dev.langchain4j.model.googleai.GoogleAiGeminiChatModel;
import dev.langchain4j.model.huggingface.HuggingFaceChatModel;
import dev.langchain4j.model.openai.OpenAiChatModel;

/**
 * The OpenAIConnector class is used to create the http-POST-request to OpenAI.
 * In order to create the request you need to define a model and an API-key (which is stored as an environment variable).
 * Four of the used prompts are displayed here as final strings.
 * Because there were 3 prototypes, a slightly different block of code for the respecting methods. There could be some refactoring done here.
 */
public class LLMConnector {

    private static final org.slf4j.Logger log = org.slf4j.LoggerFactory.getLogger(LLMConnector.class);

    private String LLM_PROVIDER;
    private String MODEL_NAME;
    private String API_KEY;

    public static final String PROMPT = "You are an AI that helps analyze and interpret FHIR resources and their validation results. " +
            "Focus on the issues with severity labeled 'fatal' or 'error' or 'warning' and provide guidance for the underlying issues and examples of what needs to be fixed. If there are several errors generated by the same source, summarize them." +
            "If you can not help with an issue, tell me." +
            "If there are no issues labeled 'fatal' or 'error' or 'warning', simply reply with: 'The resource is valid'. Nothing more. Else: keep your answer as short as possible. Return your full answer in markdown format.";

    private ChatLanguageModel model;
    private ChatMemory chatMemory;

    public static LLMConnector getConnector(CliContext cliContext) {
        return new LLMConnector(cliContext);
    }

    /**
     * Constructor for the OpenAIConnector.
     */
    private LLMConnector(CliContext cliContext) {
        LLM_PROVIDER = cliContext.getLlmProvider();
        MODEL_NAME = cliContext.getLlmModelName();
        API_KEY = cliContext.getLlmApiKey();
        initializeChatModel();
    }

    private void initializeChatModel() {
        chatMemory = MessageWindowChatMemory.builder()
            .id("12345")
            .maxMessages(10)
            .build();
        chatMemory.add(SystemMessage.from(PROMPT));
        switch (LLM_PROVIDER) {
            case "openai":
                model = OpenAiChatModel.builder()
                    .apiKey(API_KEY)
                    .modelName(MODEL_NAME)
                    .build();
                break;
            case "huggingface":
                model = HuggingFaceChatModel.builder()
                    .accessToken(API_KEY)
                    .modelId(MODEL_NAME)
                    .build();
                break;
            case "anthropic":
                model = AnthropicChatModel.builder()
                    .apiKey(API_KEY)
                    .modelName(MODEL_NAME)
                    .build();
                break;
            case "google":
                model = GoogleAiGeminiChatModel.builder()
                    .apiKey(API_KEY)
                    .modelName(MODEL_NAME)
                    .build();
                break;

            default:
                throw new IllegalArgumentException("Unsupported LLM provider: " + LLM_PROVIDER);
        }
    }

    /**
     * Remove all UserMessages from ChatMemory
     */
    private void resetChatMemory() {
        chatMemory.clear();
        chatMemory.add(SystemMessage.from(PROMPT));
    }

    /**
     * Final Prototype: Interprets the result with a LLM of OpenAI. Uses a function called createRequestBody(). Gets input from GUI.
     * @param resource The string received from the Matchbox containing the FHIR resource.
     * @param operationOutcome The string received from the Matchbox containing the validation result (OperationOutcome).
     * @return The response string from the LLM.
     */
    public String interpretWithMatchbox(String resource, String operationOutcome) {
        if (API_KEY == null) {
            return "API Key not found. Please set the matchbox.fhir.context.llm.apiKey configuration parameter.";
        }
        try {
            String requestBody = createRequestBody(resource, operationOutcome);

            chatMemory.add(UserMessage.from(requestBody));
            ChatRequest request = ChatRequest.builder()
                    .messages(chatMemory.messages())
                    .build();
            ChatResponse response = model.chat(request);

            log.info("Input Tokens: " + response.tokenUsage().inputTokenCount());
            log.info("Output Tokens: " + response.tokenUsage().outputTokenCount());
            resetChatMemory();
            // clean and return the LLMs response
            return cleanResult(response.aiMessage().text(), requestBody);
        } catch (IOException | InterruptedException e) {
            e.printStackTrace();
            return e.getMessage();
        }
    }

    /**
     * Removes the request text from the response. (certain models return the result with the original request)
     * @param result The full response string
     * @param requestBody The original request
     * @return
     */
    private String cleanResult(String result, String requestBody) {
        return result.replace(requestBody, "").replace(PROMPT, "").trim();
    }

    /**
     * Creates the request body for the LLM-request.
     * @param fhirResourceContent The ObjectNode received from calling method containing the FHIR resource.
     * @param operationOutcomeContent The ObjectNode received from the calling method containing the validation result (OperationOutcome).
     * @return The request string for the LLM.
     */
    private static String createRequestBody(Object fhirResourceContent, Object operationOutcomeContent)
            throws IOException, InterruptedException {
        String requestString = "Here is the FHIR resource: " + fhirResourceContent.toString() + "\n";
        requestString += "Here is the validation result: " + operationOutcomeContent.toString();

        return requestString;
    }
}
